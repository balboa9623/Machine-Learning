{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "LR_Multivariate_incomplete.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ijcv3K3ufXK",
        "colab_type": "text"
      },
      "source": [
        "## 1 - Packages ##\n",
        "\n",
        "First, you need to import all the packages that you will need during this assignment. \n",
        "- [numpy](www.numpy.org) is the fundamental package for scientific computing with Python.\n",
        "- [pandas](pandas.pydata.org/) is an important package for Python data analysis.\n",
        "- [matplotlib](http://matplotlib.org) is a famous library to plot graphs in Python.\n",
        "- [jdc](https://alexhagen.github.io/jdc/) : Jupyter magic that allows defining classes over multiple jupyter notebook cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9NvYXOEusGk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19c04ab8-5231-4984-b3a3-95d965f8dd5e"
      },
      "source": [
        "!pip install jdc"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jdc in /usr/local/lib/python3.6/dist-packages (0.0.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGgx8jS5ufXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import jdc\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plzs9_wiufXO",
        "colab_type": "text"
      },
      "source": [
        "## 2 - Problem Statement ##\n",
        "\n",
        "You will create a neural network class - MultivariateNetwork:\n",
        "    - initialize parameters, such as weights, learning rate, etc.\n",
        "    - implement the gredient descent algorithm\n",
        "    - implement the predict function to make predictions for new data sets\n",
        "    - implement the normalization function\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jji0CuieufXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultivariateNetwork():\n",
        "    def __init__(self, num_of_features=1, learning_rate=0.1):\n",
        "        \"\"\"\n",
        "        This function creates a vector of zeros of shape (num_of_features, 1) for W and initializes w_0 to 0.\n",
        "\n",
        "        Argument:\n",
        "        num_of_features -- size of the W vector, i.e., the number of features, excluding the bias\n",
        "        \n",
        "        \"\"\"\n",
        "        # n is the number of features\n",
        "        self.n = num_of_features\n",
        "        # alpha is the learning rate\n",
        "        self.alpha = learning_rate\n",
        "\n",
        "        ### START YOUR CODE HERE ### \n",
        "        #initialize self.W and self.w_0 to be 0's\n",
        "        self.W = np.zeros(shape=(self.n, 1))\n",
        "        self.w_0 = 0\n",
        "        ### YOUR CODE ENDS ###\n",
        "        assert(self.W.shape == (self.n, 1))\n",
        "        assert(isinstance(self.w_0, float) or isinstance(self.w_0, int))"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4TmyvZZufXS",
        "colab_type": "text"
      },
      "source": [
        "## 3 - Gradient Descent ##\n",
        "\n",
        "Forward Propagation:\n",
        "- You get X\n",
        "- You compute $h_{W}(X) = W^T * X + w_{0}\\tag{1}$\n",
        "- You calculate the cost function:  $$L(W) = \\frac{1}{2m} \\sum_{i=1}^{n} \\left(h_{W}(x^{(i)})  - y^{(i)}\\right)^2\\tag{2}$$. \n",
        "\n",
        "Here are the two formulas you will be using: \n",
        "\n",
        "$$ dw_{j} =\\frac{\\partial L}{\\partial w_{j}} = \\frac{1}{m} \\sum_{i=1}^m (( h_{W}(x^{(i)}) -y^{(i)}) * x_{j}^{(i)})\\tag{3}$$\n",
        "$$ dw_{0} = \\frac{\\partial L}{\\partial w_{0}} = \\frac{1}{m} \\sum_{i=1}^m (h_{W}(x^{(i)}) -y^{(i)})\\tag{4}$$\n",
        "\n",
        "The weights will be updated:\n",
        "$$ w_{j} = w_{j} - {\\alpha} * \\frac{\\partial L}{\\partial w_{j}}\\tag{5}$$\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3khVDmiufXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%add_to MultivariateNetwork\n",
        "def fit(self, X, Y, epochs=1000, print_loss=True):\n",
        "    \"\"\"\n",
        "    This function implements the Gradient Descent Algorithm\n",
        "    Arguments:\n",
        "    X -- training data matrix: each column is a training example. \n",
        "            The number of columns is equal to the number of training examples\n",
        "    Y -- true \"label\" vector: shape (1, m)\n",
        "    epochs --\n",
        "\n",
        "    Return:\n",
        "    params -- dictionary containing weights\n",
        "    losses -- loss values of every 100 epochs\n",
        "    grads -- dictionary containing dw and dw_0\n",
        "    \"\"\"\n",
        "    losses = []\n",
        "\n",
        "    print(\"W.T.shape = \", self.W.T.shape)\n",
        "    print(\"X.shape = \", X.shape)\n",
        "    print(\"Y.shape = \", Y.shape)\n",
        "    print(\"W.shape = \", self.W.shape)\n",
        "\n",
        "    # Get the number of training examples\n",
        "    m = X.shape[1]\n",
        "    \n",
        "    for i in range(epochs):\n",
        "\n",
        "      ### START YOUR CODE HERE ### \n",
        "      # Calculate the hypothesis outputs Y_hat (≈ 1 line of code)\n",
        "      Y_hat = np.dot(self.W.T, X) + self.w_0 #correct \n",
        "      \n",
        "      # Calculate loss (≈ 1 line of code)\n",
        "      loss = (1/(2*m)) * np.dot((Y_hat - Y), (Y_hat - Y).T) #correct\n",
        "      \n",
        "      # Calculate the gredients for W and w_0 (≈ 2 lines of code)\n",
        "      # dw = np.dot(np.sum(Y_hat - Y), X)\n",
        "      dw = np.sum((Y_hat - Y) * X)\n",
        "      dw_0 = np.sum(Y_hat - Y)\n",
        "      \n",
        "      dw /= m\n",
        "      dw_0 /= m\n",
        "\n",
        "      # Weight updates (≈ 2 lines of code)\n",
        "      self.W -= self.alpha * dw\n",
        "      self.w_0 -= self.alpha * dw_0\n",
        "      ### YOUR CODE ENDS ###\n",
        "      \n",
        "      if((i % 100) == 0):\n",
        "        losses.append(loss)\n",
        "        # Print the cost every 100 training examples\n",
        "        if print_loss:\n",
        "          print (\"Cost after iteration %i: %f\" %(i, loss))\n",
        "\n",
        "    params = {\n",
        "        \"W\": self.W,\n",
        "        \"w_0\": self.w_0\n",
        "    }\n",
        "\n",
        "    grads = {\n",
        "        \"dw\": dw,\n",
        "        \"dw_0\": dw_0\n",
        "    }\n",
        "\n",
        "    return params, grads, losses"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHaJMIttufXV",
        "colab_type": "text"
      },
      "source": [
        "### Make Predictions ###\n",
        "The predicted output is calculated as $h_{W}(X) = W^T * X + b$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbowzB1PufXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%add_to MultivariateNetwork\n",
        "def predict(self, X):\n",
        "    '''\n",
        "    Predict the actual values using learned parameters (self.W, self.w_0)\n",
        "\n",
        "    Arguments:\n",
        "    X -- data of size (n x m)\n",
        "\n",
        "    Returns:\n",
        "    Y_prediction -- a numpy array (vector) containing all predictions for the examples in X\n",
        "    '''\n",
        "    m = X.shape[1]\n",
        "    print(\"W.T shape = \", self.W.T.shape)\n",
        "    print(\"X shape = \", X.shape)\n",
        "\n",
        "\n",
        "    Y_prediction = np.zeros((1,m))\n",
        "\n",
        "    # Compute the actual values (≈ 1 line of code)\n",
        "    ### START YOUR CODE HERE ### \n",
        "    Y_prediction = np.dot(X, self.W.T) + self.w_0 #see fit function\n",
        "    #Y_prediction = self.W.T * X + self.w_0\n",
        "    #Y_prediction = self.W * X + self.w_0\n",
        "\n",
        "    ### YOUR CODE ENDS ###\n",
        "\n",
        "    return Y_prediction"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9ooB8aDufXY",
        "colab_type": "text"
      },
      "source": [
        "### Feature Scaling ###\n",
        "Here you normalize features using:\n",
        "$ \\frac{x_{i} - mean}{\\sigma}$, where $\\sigma$ is the standard deviation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9l8H0sSufXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%add_to MultivariateNetwork\n",
        "def normalize(self, matrix):\n",
        "    '''\n",
        "    matrix: the matrix that needs to be normalized. Note that each column represents a training example. \n",
        "         The number of columns is the the number of training examples\n",
        "    '''\n",
        "    # Calculate mean for each feature\n",
        "    # Pay attention to the value of axis = ?\n",
        "    # set keepdims=True to avoid rank-1 array\n",
        "    \n",
        "    ### START YOUR CODE HERE ### \n",
        "    # calculate mean (1 line of code)\n",
        "    mean = np.mean(matrix) #fix along row \n",
        "    \n",
        "    # calculate standard deviation (1 line of code)\n",
        "    std = np.std(matrix, axis=0, keepdims=True) # axis = ! #fix axis\n",
        "    \n",
        "    # normalize the matrix based on mean and std\n",
        "    matrix = (X - mean) / std\n",
        "    ### YOUR CODE ENDS ###\n",
        "\n",
        "    return matrix"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cK5fzG7sufXb",
        "colab_type": "text"
      },
      "source": [
        "### Run the Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJB1AT-XufXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRADED FUNCTION: model\n",
        "\n",
        "def Run_Experiment(X_train, Y_train, X_test, Y_test, epochs = 2000, learning_rate = 0.5, print_loss = False):\n",
        "    \"\"\"\n",
        "    Builds the multivariate linear regression model by calling the function you've implemented previously\n",
        "    \n",
        "    Arguments:\n",
        "    X_train -- training set represented by a numpy array \n",
        "    Y_train -- training labels represented by a numpy array (vector) \n",
        "    X_test -- test set represented by a numpy array\n",
        "    Y_test -- test labels represented by a numpy array (vector)\n",
        "    epochs -- hyperparameter representing the number of iterations to optimize the parameters\n",
        "    learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()\n",
        "    print_loss -- Set to true to print the cost every 100 iterations\n",
        "    \n",
        "    Returns:\n",
        "    d -- dictionary containing information about the model.\n",
        "    \"\"\"\n",
        "    num_of_features = X_train.shape[0]\n",
        "    model = MultivariateNetwork(num_of_features, learning_rate)\n",
        "    \n",
        "    \n",
        "    ### START YOUR CODE HERE ###\n",
        "    # Obtain the parameters, gredients, and losses by calling a model's method (≈ 1 line of code)\n",
        "    parameters, grads, losses = model.fit(X_train, Y_train, epochs, print_loss)\n",
        "    ### YOUR CODE ENDS ###\n",
        "    \n",
        "    ### START YOUR CODE HERE ###\n",
        "    # Predict test/train set examples (≈ 2 lines of code)\n",
        "    print(\"Y_Test shape = \", Y_test.shape)\n",
        "    Y_prediction_test = model.predict(X_test)\n",
        "    Y_prediction_train = model.predict(X_train)\n",
        "    ### YOUR CODE ENDS ###\n",
        "\n",
        "    # Print train/test Errors\n",
        "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)/Y_train) * 100))\n",
        "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)/Y_test) * 100))\n",
        "\n",
        "    W = parameters['W']\n",
        "    w_0 = parameters['w_0']\n",
        "    print(\"W is \" + str(W))\n",
        "    print(\"w_0 is \" + str(w_0))\n",
        "    \n",
        "    d = {\"losses\": losses,\n",
        "         \"Y_prediction_test\": Y_prediction_test, \n",
        "         \"Y_prediction_train\" : Y_prediction_train, \n",
        "         \"W\" : W, \n",
        "         \"w_0\" : w_0,\n",
        "         \"learning_rate\" : learning_rate,\n",
        "         \"epochs\": epochs}\n",
        "    \n",
        "    return d"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1IWwMQLufXf",
        "colab_type": "text"
      },
      "source": [
        "### Load Data and Start the Learning Process ###\n",
        "You can change num_iterations and learning_rate to see the learning process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg5Xoq_8ufXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('prj2data1.csv', header=None)\n",
        "X_train = df[[0, 1]].values.T\n",
        "Y_train = df[2].values.reshape(-1, 1).T\n",
        "\n",
        "\n",
        "df_test = pd.read_csv('prj2data1_test.csv', header=None)\n",
        "X_test = df_test[[0, 1]].values.T\n",
        "Y_test = df_test[2].values.reshape(-1, 1).T #one row by n columns "
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TolV0RoufXi",
        "colab_type": "text"
      },
      "source": [
        "### Plot the learning curve ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAU96EG-ufXi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "outputId": "0ec61b66-8cb0-406c-b279-03ed77c8be42"
      },
      "source": [
        "d = Run_Experiment(X_train, Y_train, X_test, Y_test, epochs = 1000, learning_rate = 0.01, print_loss = True)\n",
        "\n",
        "# Plot learning curve (with costs)\n",
        "losses = np.squeeze(d['losses'])\n",
        "plt.plot(losses)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs (per hundreds)')\n",
        "plt.title(\"Learning rate =\" + str(d[\"learning_rate\"]))\n",
        "plt.show()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W.T.shape =  (1, 2)\n",
            "X.shape =  (2, 1000)\n",
            "Y.shape =  (1, 1000)\n",
            "W.shape =  (2, 1)\n",
            "Cost after iteration 0: 370.221964\n",
            "Cost after iteration 100: 2.498708\n",
            "Cost after iteration 200: 2.498708\n",
            "Cost after iteration 300: 2.498708\n",
            "Cost after iteration 400: 2.498708\n",
            "Cost after iteration 500: 2.498708\n",
            "Cost after iteration 600: 2.498708\n",
            "Cost after iteration 700: 2.498708\n",
            "Cost after iteration 800: 2.498708\n",
            "Cost after iteration 900: 2.498708\n",
            "Y_Test shape =  (1, 7)\n",
            "W.T shape =  (1, 2)\n",
            "X shape =  (2, 7)\n",
            "W.T shape =  (1, 2)\n",
            "X shape =  (2, 1000)\n",
            "train accuracy: 74.61005929316505 %\n",
            "test accuracy: 73.03190179110072 %\n",
            "W is [[3.3271448]\n",
            " [3.3271448]]\n",
            "w_0 is 7.4524096923051575\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCOn8LZxHn2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 99,
      "outputs": []
    }
  ]
}