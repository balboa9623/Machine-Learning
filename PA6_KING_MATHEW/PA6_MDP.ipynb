{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PA6_MDP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTzt3E00LwN5",
        "outputId": "6c3cf83b-0157-4d34-96e9-5e20a19a88db"
      },
      "source": [
        "!pip install jdc"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jdc in /usr/local/lib/python3.6/dist-packages (0.0.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGQEYH0nNcfF"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import jdc"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an-WX01o6c4y"
      },
      "source": [
        "class MDP():\n",
        "  def __init__(self, num_state, num_actions, filename, gamma):\n",
        "    self.num_states = num_state\n",
        "    self.num_actions = num_actions\n",
        "    self.filename = filename\n",
        "    self.gamma = gamma\n",
        "\n",
        "    self.stateDic = {}\n",
        "    self.rewardArr = [[] for i in range(self.num_states)]\n",
        "    \n",
        "\n",
        "    self.read_from_file()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXTmZowvNZMq"
      },
      "source": [
        "%%add_to MDP\n",
        "def read_from_file(self):\n",
        "  file = open(self.filename, \"r\")\n",
        "\n",
        "  data_obj = []\n",
        "  \n",
        "  for line in file:\n",
        "    data_obj.append(line)\n",
        "\n",
        "  file.close()\n",
        "\n",
        "  print(data_obj)\n",
        "\n",
        "  for i, obj in enumerate(data_obj):\n",
        "    obj = obj.rstrip()\n",
        "    obj = obj.split(\"(\")\n",
        "    obj = \"\".join(obj)\n",
        "    obj = obj.split(\")\")\n",
        "    obj = \"\".join(obj)\n",
        "    obj = obj.split(\" \")\n",
        "    data_obj[i] = obj\n",
        "\n",
        "  for x, obj in enumerate(data_obj):\n",
        "    action = {}\n",
        "    for a in range(self.num_actions):\n",
        "      i = a+1\n",
        "      action['a'+str(i)] = []\n",
        "    self.stateDic[obj[0]] = {\"reward\":int(obj[1]), \"actions\": action}\n",
        "    self.rewardArr[x].append(int(obj[1]))\n",
        "    \n",
        "\n",
        "  # self.stateDic[\"s1\"][\"actions\"][\"a1\"].append({\"s1\": 0.509})\n",
        "  # self.stateDic[\"s1\"][\"actions\"][\"a1\"].append({\"s2\": 0.491})\n",
        "\n",
        "  # print(data_obj[2])\n",
        "\n",
        "  for obj in data_obj:\n",
        "    idx = 3\n",
        "    for action in obj[2::3]:\n",
        "      self.stateDic[obj[0]][\"actions\"][action].append({obj[idx]: float(obj[idx+1])})\n",
        "      idx += 3\n",
        "  \n",
        "  print(self.stateDic)\n",
        "  print(self.rewardArr)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlVLzHKbcq5m"
      },
      "source": [
        "%%add_to MDP\n",
        "def Bellman_equation(self):\n",
        "  \"\"\"\n",
        "  E.g., [a1] ==> J^2(s1) = (r(s1) = 5) + ((gamma = 0.8)*( ((Prob(a1, s1) = 0.509) * J^1(s1) = 5)  +  ((Prob(a1, s2) = 0.491) * J^1(s2) = 10))\n",
        "        [a2] ==> J^2(s1) = (r(s1) = 5) + ((gamma = 0.8)*( ((Prob(a1, s1) = 0.31) * J^1(s1) = 5)  +  ((Prob(a1, s3) = 0.69) * J^1(s3) = -5))\n",
        "        J^2(s1) = max(a1, a2)\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # states = {\"s1\": 0, \"s2\": 1, \"s3\": 2} # 0: \"s1\", 1: \"s2\", 2: \"s3\"}\n",
        "  states = {}\n",
        "  for i in range(self.num_states):\n",
        "    states[\"s\"+str(i+1)] = i\n",
        "  print(states) \n",
        "\n",
        "  for k in range(1,20): # 20):\n",
        "    # print(\"k = \", k)\n",
        "    for state, st_idx in states.items():\n",
        "      reward = self.stateDic[state][\"reward\"]\n",
        "      # print(state)\n",
        "      # print(reward)\n",
        "      tmp_j_si = []\n",
        "      rew_idx = 0\n",
        "      for action in self.stateDic[state][\"actions\"]:\n",
        "        # print(action)\n",
        "        num_state_trans = len(self.stateDic[state][\"actions\"][action])\n",
        "        j_sum = 0\n",
        "        for trans_idx in range(num_state_trans):\n",
        "          s_lst = list(self.stateDic[state][\"actions\"][action][trans_idx])[0] # get the states inside the action list\n",
        "          # print(\"{} -> r = {}\".format( s_lst, self.rewardArr[states[s_lst]][k-1] ) )\n",
        "\n",
        "          j_sum += ( self.stateDic[state][\"actions\"][action][trans_idx][s_lst] * self.rewardArr[states[s_lst]][k-1] )\n",
        "        j_si = reward + (self.gamma * j_sum)\n",
        "        j_si = round(j_si, 3)\n",
        "        # print(j_si)\n",
        "        tmp_j_si.append(j_si)\n",
        "      self.rewardArr[st_idx].append(max(tmp_j_si))\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKSbakoGDVub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16ebf277-1885-44e0-bba8-0060189d2755"
      },
      "source": [
        "n_state = 3\n",
        "n_actions = 2\n",
        "filename = 'test1.in'\n",
        "\n",
        "# n_state = 10 # 3\n",
        "# n_actions = 3 # 2\n",
        "# filename = 'test2.in'\n",
        "discount = 0.8\n",
        "mdp = MDP(n_state, n_actions, filename, discount)\n",
        "mdp.Bellman_equation()\n",
        "\n",
        "st = {}\n",
        "\n",
        "for i in range(mdp.num_states):\n",
        "  st[i] = \"s\"+str(i+1)\n",
        "print(st)\n",
        "\n",
        "for i, val in st.items():\n",
        "  print(\"{} ==> {}\". format(val, mdp.rewardArr[i]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['s1 5 (a1 s1 0.509) (a1 s2 0.491) (a2 s1 0.31) (a2 s3 0.69)\\n', 's2 10 (a1 s1 0.4) (a1 s2 0.3) (a1 s3 0.3) (a2 s2 0.5) (a2 s3 0.5)\\n', 's3 -5 (a1 s1 0.3) (a1 s2 0.3) (a1 s3 0.4) (a2 s1 0.2) (a2 s2 0.8)\\n']\n",
            "{'s1': {'reward': 5, 'actions': {'a1': [{'s1': 0.509}, {'s2': 0.491}], 'a2': [{'s1': 0.31}, {'s3': 0.69}]}}, 's2': {'reward': 10, 'actions': {'a1': [{'s1': 0.4}, {'s2': 0.3}, {'s3': 0.3}], 'a2': [{'s2': 0.5}, {'s3': 0.5}]}}, 's3': {'reward': -5, 'actions': {'a1': [{'s1': 0.3}, {'s2': 0.3}, {'s3': 0.4}], 'a2': [{'s1': 0.2}, {'s2': 0.8}]}}}\n",
            "[[5], [10], [-5]]\n",
            "{'s1': 0, 's2': 1, 's3': 2}\n",
            "{0: 's1', 1: 's2', 2: 's3'}\n",
            "s1 ==> [5, 10.964, 14.492, 17.621, 20.004, 21.947, 23.489, 24.726, 25.714, 26.505, 27.138, 27.644, 28.049, 28.373, 28.632, 28.84, 29.006, 29.139, 29.245, 29.33]\n",
            "s2 ==> [10, 12.8, 17.108, 19.93, 22.406, 24.317, 25.869, 27.103, 28.092, 28.883, 29.516, 30.022, 30.427, 30.751, 31.01, 31.217, 31.384, 31.516, 31.623, 31.708]\n",
            "s3 ==> [-5, 2.2, 4.946, 8.268, 10.575, 12.54, 14.074, 15.314, 16.302, 17.093, 17.726, 18.232, 18.637, 18.961, 19.22, 19.428, 19.593, 19.727, 19.832, 19.918]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ_nBdHohnvc"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}