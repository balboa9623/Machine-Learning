{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "DT_Part-I.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCNobwHbZ1sq"
      },
      "source": [
        "## 1 - Packages ##\n",
        "\n",
        "First, you need to import all the packages that you will need during this assignment. \n",
        "- [numpy](www.numpy.org) is the fundamental package for scientific computing with Python.\n",
        "- [pandas](pandas.pydata.org/) is an important package for Python data analysis.\n",
        "- [jdc](https://alexhagen.github.io/jdc/) : Jupyter magic that allows defining classes over multiple jupyter notebook cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vNm05phZ1sr",
        "outputId": "2ccfd56e-82fe-425d-9836-dadd5e7e6692",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install jdc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import jdc"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jdc in /usr/local/lib/python3.6/dist-packages (0.0.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqPc-8-4Z1st"
      },
      "source": [
        "## 2 - Required Methods ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju-PmcHOZ1su"
      },
      "source": [
        "### 2.1 - How to display the column names of a given dataset ###\n",
        "- Pandas [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)\n",
        "- Pandas [pandas.DataFrame.columns](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.columns.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgxZGNLKZ1su",
        "outputId": "a4049eb0-ddf7-4c50-b3c8-149ce844a158",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Define a DataFrame object\n",
        "df_sample = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
        "                   columns=['a', 'b', 'c'])\n",
        "\n",
        "# print the content of the DataFrame\n",
        "print(df_sample)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   a  b  c\n",
            "0  1  2  3\n",
            "1  4  5  6\n",
            "2  7  8  9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "s9rnY2-VZ1sw",
        "outputId": "a0a894c5-7ed7-4767-c629-6af1eabecd97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Print the column names of the dataset\n",
        "print(df_sample.columns)\n",
        "print(df_sample.columns[0])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['a', 'b', 'c'], dtype='object')\n",
            "a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fBP2oJFZ1sz"
      },
      "source": [
        "#### Graded Excercise #### \n",
        "Print out the column names of the training set that will be used in this assignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gOX0LHlZ1sz",
        "outputId": "142b7d2c-e292-4447-9d29-99d7e8aa7d36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Will be graded\n",
        "\n",
        "# Load the training data that we will use in this assignment\n",
        "df_train = pd.read_csv('train.csv')\n",
        "\n",
        "# Print the column names of the training data\n",
        "### START CODE HERE ### (≈ 1 line of code)\n",
        "# Replace ??? with the correct code\n",
        "print( df_train.columns )\n",
        "### END CODE HERE ###"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['wesley', 'romulan', 'poetry', 'honor', 'tea', 'barclay', 'class'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcROHkgHZ1s1"
      },
      "source": [
        "### 2.2 - How to determine the unique values in a given array ###\n",
        "- [numpy.unique](https://numpy.org/doc/stable/reference/generated/numpy.unique.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxGD9so7Z1s1",
        "outputId": "6edc2630-8a2a-493f-8de6-c89e475fa4c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Return the unique values in an array\n",
        "arr = np.array([1, 1, 1, 1, 2, 2, 2, 3, 3, 4])\n",
        "np.unique(arr)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXfWOrfpZ1s3",
        "outputId": "4acfeed3-16a5-4ecd-84e8-95177e2c2f4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Return both the unique values and the count of each value\n",
        "np.unique(arr, return_counts=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1, 2, 3, 4]), array([4, 3, 2, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "CBqr-BqhZ1s6",
        "outputId": "fe3c3344-68f3-4134-b33c-217bdbfbed4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# You can store the uniuqe values and their counts in variables\n",
        "values, counts = np.unique(arr, return_counts=True)\n",
        "print(\"Unique values are\", values)\n",
        "print(\"Corresponding counts are\", counts)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique values are [1 2 3 4]\n",
            "Corresponding counts are [4 3 2 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTg-fnz6Z1s8"
      },
      "source": [
        "#### Graded Excercise #### \n",
        "Print out the unique values in the column of \"wesley\" and their corresponding counts\n",
        "- hint: the \"wesley\" column can be obtained by using df['wesley']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "uIPrG9rvZ1s8",
        "outputId": "ca0c24ec-d82d-4ebd-87a7-9a31ae3a1039",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### START CODE HERE ### (≈ 1 line of code)\n",
        "values, counts = np.unique(df_train['wesley'], return_counts=True)\n",
        "### END CODE HERE ###\n",
        "print(\"Unique values in 'wesley' are\", values)\n",
        "print(\"Corresponding counts are\", counts)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique values in 'wesley' are [0 1]\n",
            "Corresponding counts are [408 392]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSWcbniPZ1s-"
      },
      "source": [
        "### 2.3 - DataFrame.where ###\n",
        "-[DataFrame.where](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.where.html)\n",
        "- Identify a subset based on certain conditions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "nLTBsqCPZ1s-",
        "outputId": "51884678-d625-48ba-8b62-29a1438c3f96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "# For df_sample above, we want to find out items whose a >= 4\n",
        "df_sample.where(df_sample['a'] >= 4)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     a    b    c\n",
              "0  NaN  NaN  NaN\n",
              "1  4.0  5.0  6.0\n",
              "2  7.0  8.0  9.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqKsODHKZ1tA"
      },
      "source": [
        "As you can see, if items are evaluated to be false, they are replaced by \"NaN\".\n",
        "- [DataFrame.dropna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html)\n",
        "- It can drop the \"NaN\" rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B1LEkDjZ1tB",
        "outputId": "e5c777c9-5c0c-4dd7-acfc-4ef2f5617370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "df_sample.where(df_sample['a'] >= 4).dropna()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     a    b    c\n",
              "1  4.0  5.0  6.0\n",
              "2  7.0  8.0  9.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyRRMWB0Z1tD",
        "outputId": "6b46a9c0-7431-4512-88c5-107ba322f47e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Drop NaN and return a specific column\n",
        "df_sample.where(df_sample['a'] >= 4).dropna()['a']"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    4.0\n",
              "2    7.0\n",
              "Name: a, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFa16zTlZ1tF"
      },
      "source": [
        "#### Graded Exercise ####\n",
        "- Return the list of items where tea=1 in our training set\n",
        "- Only show the \"class\" column in your result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX76HxI4Z1tF",
        "outputId": "ad91edf8-418e-4b30-b4e5-8380add9574f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### START CODE HERE ###\n",
        "# Replace ??? with the correct code\n",
        "df_train.where(df_train['tea'] == 1).dropna()['class']\n",
        "### END CODE HERE ###"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2      0.0\n",
              "7      1.0\n",
              "9      1.0\n",
              "10     1.0\n",
              "15     0.0\n",
              "      ... \n",
              "788    0.0\n",
              "792    0.0\n",
              "793    0.0\n",
              "797    1.0\n",
              "799    0.0\n",
              "Name: class, Length: 403, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfXgvu0mZ1tH"
      },
      "source": [
        "## 3 - Fundamentals in Decision Tree ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOCZ5rEoZ1tI"
      },
      "source": [
        "### 3.1 - Entropy ###\n",
        "- As usual, we will define a class named \"Decision_Tree\"\n",
        "- We will implement entropy function:\n",
        "$$ H = -\\sum_{i=1}^{n} P_{i} * \\log_{2}P_{i}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMoAGRGyZ1tI"
      },
      "source": [
        "class Decision_Tree():\n",
        "    def entropy(self, column):\n",
        "        \"\"\"\n",
        "        Calculate the entropy of a given data column.\n",
        "        column: the data column\n",
        "        \"\"\"\n",
        "        \n",
        "        # the list that will contain every -pi * log(pi)\n",
        "        ent_list = []\n",
        "        # print(len(column))\n",
        "        \n",
        "        ### START CODE HERE ###\n",
        "        # Determine the unique values in the column and their corresponding counts of each unique value\n",
        "        values, counts = np.unique(column, return_counts=True)\n",
        "        # print(values)\n",
        "        # print(counts)\n",
        "        \n",
        "        # The number of disctint values\n",
        "        num_distinct_values = len(values)\n",
        "        # the total number of items in the column\n",
        "        total_items_in_column = len(column)\n",
        "        \n",
        "        for i in range(num_distinct_values):\n",
        "            # calculate the probability pi for the ith value \n",
        "            p_i = counts[i]/np.sum(counts)\n",
        "            # calculate -pi * log(pi)\n",
        "            ent_i =  -p_i * np.log2(p_i)\n",
        "            #put the result into the list\n",
        "            ent_list.append(ent_i)\n",
        "        \n",
        "        ### END CODE HERE ###\n",
        "\n",
        "        return np.sum(ent_list)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFGAB-5BZ1tK"
      },
      "source": [
        "### 3.2 - Information Gain ###\n",
        "$$ IG(S|a) = entropy(S) - \\sum_{v \\in values(a)} \\frac {|S_{v}|} {|S|} * entropy(S_{v})$$\n",
        "where\n",
        "- $IG(S|a)$ means the information gain if we split data S using attribute a\n",
        "- $|S_{v}|$ means the number of items with $a = v$\n",
        "- $|S|$ means the total number of items in S\n",
        "- $\\frac {|S_{v}|} {|S|}$ is the probability of $ a = v $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzx_d_JbZ1tK"
      },
      "source": [
        "%%add_to Decision_Tree\n",
        "def Infomation_Gain(self, S, entropy_before_splitting, a, class_name = \"class\"):\n",
        "    \"\"\"\n",
        "    Calculate the information gain of a dataset. This function takes four parameters:\n",
        "    1. S: the overall dataset (See the equation above)\n",
        "    2. entropy_before_splitting: the entropy before splitting\n",
        "    3. a: the attribute that we will use to split the data (See the equation above)\n",
        "    4. class_name = the class that the set of data is classified as\n",
        "    \"\"\"    \n",
        "    # the list that will contain the weighted entropy of each child, i.e., Pv * Hv, \n",
        "    #       where Pv is the probability of being in the child node v, and\n",
        "    #       Hv is the entropy of child node v: entropy(Sv).\n",
        "    H_list = []\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    #determine the unique values and their corresponding counts for the split attribute \n",
        "    unique_vals, counts= np.unique(S[a], return_counts=True)\n",
        "    \n",
        "    #calculate the total number of items in S\n",
        "    total_S = len(S)\n",
        "    #Calculate the total number of unnique values with regard to attribute a\n",
        "    total_Sv = len(unique_vals)\n",
        "\n",
        "    # print(unique_vals)\n",
        "    # print(counts)\n",
        "    # print(S, \"\\n\")\n",
        "    # print(entropy_before_split)\n",
        "    # print(a, \"\\n\")\n",
        "    # print(len(unique_vals))\n",
        "    # print(len(S))\n",
        "    \n",
        "    for i in range(total_Sv):\n",
        "        # the probablity of being in the ith child node\n",
        "        P_i = counts[i]/np.sum(counts)\n",
        "        # the value v of the ith child\n",
        "        v = unique_vals[i]\n",
        "        # the subset Sv, where a = v\n",
        "        # hint: use DataFrame.where and only return the \"class\" column\n",
        "        S_v = S.where(S[a] == v).dropna()[class_name]\n",
        "        # the entropy of child node Sv\n",
        "        H_i = self.entropy(S_v)\n",
        "        # put P_i * H_i into the H_list \n",
        "        H_list.append(P_i * H_i)\n",
        "    \n",
        "    # calculate the conditional entropy based on H_list\n",
        "    conditional_entropy = np.sum(H_list)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    #Calculate the information gain\n",
        "    Information_Gain = entropy_before_splitting - conditional_entropy\n",
        "    return Information_Gain"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exB8naXZZ1tM"
      },
      "source": [
        "## 4 - Experiment ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRt1851eZ1tM",
        "outputId": "d83c85f1-752f-40ea-e778-8578ce2bc6d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "DT = Decision_Tree()\n",
        "\n",
        "### START CODE HERE ###\n",
        "# Data set has been obtained in df_train above\n",
        "# Calculate the entropy before splitting based on df_train\n",
        "entropy_before_split = DT.entropy(df_train)\n",
        "print(\"Entropy before splitting is \", entropy_before_split)\n",
        "# \n",
        "#calcuate the information gain for attribute \"ig\"\n",
        "ig = DT.Infomation_Gain(df_train, entropy_before_split, 'barclay')\n",
        "print(\"Information gain for barclay is \", ig)\n",
        "### END CODE HERE ###"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entropy before splitting is  0.9965700521510767\n",
            "Information gain for barclay is  0.16029078947930264\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE2ZEWUlZ1tO"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}